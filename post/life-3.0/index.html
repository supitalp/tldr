<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="theme-color" content="#263238">

<meta name="generator" content="Hugo 0.37.1" />

<link rel="apple-touch-icon" href="https://supitalp.github.io/tldr/images/logo.png">


<link rel="canonical" href="https://supitalp.github.io/tldr/post/life-3.0/">


    <link href="//fonts.googleapis.com/css?family=Noto+Sans:400,700|Montserrat" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Life 3.0 - Being Human in the Age of Artificial Intelligence - tl;dr</title>
    
<meta property="og:title" content="Life 3.0 - Being Human in the Age of Artificial Intelligence - tl;dr">
<meta property="og:type" content="article">
<meta property="og:url" content="https://supitalp.github.io/tldr/post/life-3.0/">
<meta property="og:image" content="https://supitalp.github.io/tldr/images/life-3.0.jpg">
<meta property="og:site_name" content="tl;dr">
<meta property="og:description" content="This book is one of the most information dense one that I&amp;rsquo;ve read this year (perhaps only The Blind Watchmaker could compete on that respect). For this reason, I will mostly write down my favorite excerpts of the book here, along with some further explanations.Life: Process that can retain its complexity and replicate.The three stages of life: Life 1.0 (the biological stage): cannot change its software or hardware Life 2.">
<meta property="og:locale" content="ja_JP">

<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="tl;dr">
<meta name="twitter:url" content="https://supitalp.github.io/tldr/post/life-3.0/">
<meta name="twitter:title" content="Life 3.0 - Being Human in the Age of Artificial Intelligence - tl;dr">
<meta name="twitter:description" content="This book is one of the most information dense one that I&amp;rsquo;ve read this year (perhaps only The Blind Watchmaker could compete on that respect). For this reason, I will mostly write down my favorite excerpts of the book here, along with some further explanations.Life: Process that can retain its complexity and replicate.The three stages of life: Life 1.0 (the biological stage): cannot change its software or hardware Life 2.">
<meta name="twitter:image" content="https://supitalp.github.io/tldr/images/life-3.0.jpg">


<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "Article",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https://supitalp.github.io/tldr/"
    },
    "headline": "Life 3.0 - Being Human in the Age of Artificial Intelligence - tl;dr",
    "image": {
      "@type": "ImageObject",
      "url": "https://supitalp.github.io/tldr/images/life-3.0.jpg",
      "height": 700,
      "width": 700
    },
    "datePublished": "2017-10-22T09:00:00JST",
    "dateModified": "2017-10-22T09:00:00JST",
    "author": {
      "@type": "Person",
      "name": "tl;dr",
      "image": "https://supitalp.github.io/tldr/images/logo.png"
    },
    "publisher": {
      "@type": "Organization",
      "name": "tl;dr",
      "logo": {
        "@type": "ImageObject",
        "url": "https://supitalp.github.io/tldr/images/logo.png",
        "height": 60,
        "width": 60
      }
    },
    "description": "This book is one of the most information dense one that I&amp;rsquo;ve read this year (perhaps only The Blind Watchmaker could compete on that respect). For this reason, I will mostly write down my favorite excerpts of the book here, along with some further explanations.
Life: Process that can retain its complexity and replicate.
The three stages of life:
 Life 1.0 (the biological stage): cannot change its software or hardware Life 2."
  }
</script>


    <style>
      html { font-size: 18px;}@media (max-width: 768px) { html { font-size: 15px; }}body { font-family: 'Noto Sans','Hiragino Kaku Gothic Pro',メイリオ,Meiryo,sans-serif; font-size: inherit; font-weight: 300; line-height: 1rem; background-color: #eceff1;}p { margin: 0;}a { color: #4caf50;}a:hover { text-decoration: none; color: #388e3c;}ul,ol { margin: 0; padding: 0;}h1, h2, h3, h4, h5, h6 { margin: 0; font-weight: 700;}h1 { font-size: 1.8rem; line-height: 2rem; margin: 1.5rem 0; }h2 { font-size: 1.4rem; line-height: 2rem; margin: 1.5rem 0; }h3 { font-size: 1.2rem; line-height: 1.5rem; margin: 1.5rem 0; }h4, h5, h6 { font-size: 1rem; line-height: 1.5rem; margin: 1.5rem 0; }main { display: block;}.content-inner { padding: 1rem 2rem;}.content-inner.thin { padding: .5rem 1rem;}@media (max-width: 768px) { .content-inner { padding: 1rem; }}/* Override */.container { position: relative;}/* Parts:layouts */.l-header { background-color: #fff; margin-bottom: 1rem; padding: 1rem 0; text-align: center;}.l-footer { font-size: .8rem; padding: 1.5rem 0;}/* Parts:menu */.p-menu { position: absolute; right: 15px; top: 0;}/* Parts:terms */.p-terms { list-style: none;}.p-terms .terms-title { margin: 0;}.p-terms a { display: inline-block; padding: .25rem 0;}.p-terms.inline li { display: inline-block; font-size: .8rem;}.p-terms.inline li::after { content: ',';}.p-terms.inline li:last-child::after { content: '';}/* Parts:paging */.p-paging { margin-bottom: 1.5rem; text-align: center;}.p-paging a { display: inline-block; padding: 1rem 1.5rem; margin: 0 .5rem; background-color: #cfd8dc; color: #263238;}/* Parts:section */section { margin-bottom: 1.5rem;}section>header { font-size: .8rem; font-weight: 700; margin-bottom: .5rem; text-transform: uppercase;}section>header a { color: #333; text-decoration: underline;}section.article-footer { margin-bottom: 1rem;}section.article-footer>header { margin-bottom: 0;}/* Parts:logo */.p-logo { display: inline-block; font-family: 'Montserrat', sans-serif; text-transform: uppercase;}.p-logo a { display: inline-block; font-size: 1.4rem; line-height: 2rem; color: #000;}/* Parts:crumb */.p-crumb ol { list-style: none; margin-bottom: 1rem;}.p-crumb li { display: inline; margin-right: .25rem; font-size: .8rem; color: #607d8b;}.p-crumb li::after { content: '/'; margin-left: .25rem;}.p-crumb li:last-child::after { content: '';}/* Parts:facts */.p-facts { list-style: none; font-size: .8rem; margin-bottom: 1rem;}.p-facts li { display: inline-block; margin-right: .5rem; color: #90a4ae;}.p-facts li i { margin-right: .5rem; color: #cfd8dc;}/* Parts:article */article { background-color: #fff;}article .title { margin: 0; margin-bottom: .5rem; font-weight: 700;}article .title a { color: #000;}article .thumb { display: block; background-image: url(https://supitalp.github.io/tldr/images/default.jpg); background-position: center; background-size: cover;}article .summary { margin-bottom: .5rem; max-height: 5rem; overflow: hidden;}article.single .thumb { height: 18rem;}@media (max-width: 768px) { article.single .thumb { height: 12rem; }}article.li { margin-bottom: 1rem;}article.li .thumb { height: 7.5rem; margin-bottom: .5rem;}article.li.sm { background-color: transparent; margin-bottom: .5rem;}article.li.sm>header { padding: .5rem 0;}article.li.sm .title { font-size: .8rem; line-height: 1rem; margin-bottom: .25rem;}article.li.sm .p-facts { font-size: .6rem; margin-bottom: 0;}article.li.sm .thumb { float: left; margin-right: .5rem; height: 3rem; width: 3rem;}.article-body h2 { padding: 1rem 0; border-bottom: 2px solid #eceff1;}.article-body h2:first-child { margin-top: 0; }.article-body h3 { color: #428bca;}.article-body h4 { border-left: solid .25rem #428bca; padding: 0 .5rem;}.article-body p { margin: 1.5rem 0; line-height: 1.5rem;}.article-body a { text-decoration: underline;}.article-body ul,.article-body ol { padding-left: 1.5rem;}.article-body code { display: inline-block; font-family: Menlo, consolas, monospace; font-size: .8rem; padding: 0 .5rem; line-height: 1.5rem;}.article-body pre { margin: 1.5rem 0; padding: 0; font-size: .8rem; border: none; border-radius: 0;}.article-body pre code { display: block; line-height: 1rem; padding: 1rem;}.article-body blockquote { margin: 1.5rem 0; padding: .5rem 0; font-size: .8rem; border-top: 1px solid #eceff1; border-bottom: 1px solid #eceff1; color: #607d8b;}.article-body blockquote p { margin: .5rem 0; line-height: 1rem;}.article-body strong { box-shadow: 0 -.5rem 0 0 #90caf9 inset;}.article-body em { font-style: normal; font-weight: 700; color: #03a9f4;}.article-body figure { margin: 1.5rem 0; }.article-body figure img { max-width: 100%; }.article-body figure.left,.article-body figure.right { width: 15rem; height: 12rem; margin-top: 0;}.article-body figure.left { float: left; margin-right: 1rem; }.article-body figure.right { float: right; margin-left: 1rem; }@media (max-width: 768px) { .article-body figure.left, .article-body figure.right { float: none; margin: 0; width: auto; height: auto; }}.article-body figcaption { padding: .5rem 0; font-size: .8rem; text-align: center;}.article-body figcaption a { color: #263238;}
    </style>
  </head>

  <body>
    
    
    

    <header class="l-header">
      <div class="container">
        <div class="p-logo">
          <a href="https://supitalp.github.io/tldr/">tl;dr</a>
        </div>
      </div>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    <nav class="p-crumb">
      <ol>
        <li><a href="https://supitalp.github.io/tldr/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
        
        <li itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="https://supitalp.github.io/tldr/post/" itemprop="url"><span itemprop="title">post</span></a></li>
        
        <li class="active">Life 3.0 - Being Human in the Age of Artificial Intelligence</li>
      </ol>
    </nav>

    <article class="single">

  <a href="https://supitalp.github.io/tldr/post/life-3.0/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/life-3.0.jpg);"></a>
  <div class="content-inner">
    <h1>Max Tegmark / Life 3.0 - Being Human in the Age of Artificial Intelligence</h1>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-10-22T09:00:00JST">Oct 22, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
      
    </ul>

    <div class="article-body">

<p>This book is one of the most information dense one that I&rsquo;ve read this year (perhaps only <em>The Blind Watchmaker</em> could compete on that respect). For this reason, I will mostly write down my favorite excerpts of the book here, along with some further explanations.</p>

<p><em>Life</em>: Process that can retain its complexity and replicate.</p>

<p>The three stages of life:</p>

<ul>
<li>Life 1.0 (the biological stage): cannot change its software or hardware</li>
<li>Life 2.0 (cultural stage): can change its software (through learning), but cannot change its hardware)</li>

<li><p>Life 3.0 (technological stage): can change its hardware and its software)</p></li>

<li><p>No one known when AGI (Artifical General Intelligence) will emerge.</p></li>

<li><p>The topic of &ldquo;consciousness&rdquo; is irrelevant to the AI discussion. Rather, we should think about it in terms of goals.</p></li>
</ul>

<blockquote>
<p>if you get struck by a driverless car, it makes no difference to you whether it subjectively feels conscious</p>
</blockquote>

<p><em>Intelligence</em>: Ability to accomplish complex goals.</p>

<ul>
<li><p>Moravec&rsquo;s paradox: the fact that low-level sensorimotor tasks seem easy despite requiring enormous computational resources.</p></li>

<li><p>Moravec&rsquo;s landscape metaphor
<img src="https://supitalp.github.io/tldr/images/life-3.0-moravec-landscape.png" alt="Moravec's intelligence landmscape" style="width: 100%;"/></p></li>
</ul>

<p>Recent breakthroughs in AI:</p>

<ul>
<li><p>Breakout + Atari games solved using Deep Reinforcement Learning <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">video</a></p></li>

<li><p>AlphaGo <a href="https://www.youtube.com/watch?v=JNrXgpSEEIE">Move 37, Game 2</a> where AlphaGo played on the 5th row, a very unconventional move that turned out to be a genius, creative move.</p></li>

<li><p>Natural Language Processing (NLP): in particular for translation tasks. However, the <a href="http://commonsensereasoning.org/winograd.html">Winograd Challenge</a> is still out of reach.</p></li>
</ul>

<blockquote>
<p>the goal of an AI is independent of its intelligence</p>

<p>The only goal of a chess com­puter is to win at chess, but there are also com­puter tour­na­ments in so-called los­ing chess, where the goal is the ex­act op­pos­ite, and the com­puters com­pet­ing there are about as smart as the more com­mon ones pro­grammed to win.</p>
</blockquote>

<ul>
<li>The goals of a super-intelligent AI might seem pointless to us:</li>
</ul>

<blockquote>
<p>The paper clip maximizer turns as many of Earth’s atoms as possible into paper clips and rapidly expands its factories into the cosmos. It has nothing against humans, and kills us merely be­cause it needs our atoms for paper clip production.</p>
</blockquote>

<ul>
<li>About Moravec virus: the fastest way a galactic civilization might expand is through sending signals through space (at the speed of light), transmitting a program, that, if executed by potential receivers, would be programmed to take over the civilization. Some kind of intergalactic virus&hellip;</li>
</ul>

<blockquote>
<p>broadcasting a message that tricks naive freshly evolved civilizations into building a super­intelligent ma­chine that hijacks them, a civilization can expand essentially at the speed of light, the speed at which their seductive siren song spreads through the cosmos. Since this may be the only way for advanced civilizations to reach most of the galaxies within their future light cone&rdquo;. &ldquo; they have little incentive not to try it, we should be highly suspicious of any transmissions from extraterrestrials!</p>
</blockquote>

<h2 id="the-next-10-000-years">The Next 10 000 years</h2>

<p>Max Tegmark explores many different scenarios regarding the next 10 000 years to come. Among which:</p>

<ul>
<li>Descendants: AIs behave as our worthy descendants, and make sure humans have a nice way out:</li>
</ul>

<blockquote>
<p>Every human is offered an adorable robotic child with superb social skills who learns from them, adopts their values and makes them feel proud and loved. Humans are gradually phased out via a global one-child policy, but are treated so exquisitely well until the end that they feel they’re in the most fortunate generation ever.</p>
</blockquote>

<ul>
<li>About the relationships between a super AI and humans:</li>
</ul>

<blockquote>
<p>It’s generally hard for two entities thinking at dra­matically different speeds and with extremely disparate capabilities to have meaningful communication as equal</p>
</blockquote>

<ul>
<li>Zookeeper:</li>
</ul>

<blockquote>
<p>an omnipotent super­in­telligent AI keeps some humans around, who feel treated like zoo animals and occasionally lament their fate.</p>
</blockquote>

<ul>
<li>Reversion:</li>
</ul>

<blockquote>
<p>After the Omegas took over the world as in the opening of the book, a massive global propaganda campaign was launched that romanticized the simple farming life of 1,500 years ago. Earth’s population was reduced to about 100 million people by an engineered pandemic blamed on terrorists. The pandemic was secretly targeted to ensure that nobody who knew anything about science or technology survived. With the excuse of eliminating the infection hazard of large concentrations of people, Prometheus-controlled robots emptied and razed all cities. Survivors were given large tracts of (suddenly available) land and educated in sustainable farming, fishing and hunting practices using only early medieval technology. In the meantime, armies of robots systematically removed all traces of modern technology (including cities, factories, power lines and paved roads), and thwarted all human attempts to document or re-create any such technology. Once the technology was globally forgotten, robots helped dismantle other robots until there were almost none left. The very last robots were deliberately vaporized together with Prometheus itself in a large thermonuclear explosion. There was no longer any need to ban modern technology, since it was all gone. As a result, humanity bought itself over a millennium of additional time without worries about either AI or totalitarianism.</p>
</blockquote>

<ul>
<li>Self-destruction:</li>
</ul>

<blockquote>
<p>One candidate for the dooms­day device is a huge underground cache of so-called salted nukes, preferably humongous hydrogen bombs surrounded by massive amounts of cobalt. Physicist Leo Szilard argued already in 1950 that this could kill every­one on Earth: the hydrogen bomb explosions would render the cobalt ra­dioactive and blow it into the stratospher</p>
</blockquote>

<h2 id="our-cosmic-endowment-the-next-billion-years-and-beyond">Our Cosmic Endowment: The Next Billion Years and Beyond</h2>

<p>Paradoxically, Max Tegmark argues that it is easier to predict what might happen if a superintelligent AI rules the universe in the next billion years, because the possibilities there would only be limited by the laws of physics (those we know, and those we do not know yet&hellip;). Actually, given our current known laws of physics, what we can predict is just a lower bound of what would actually be feasible.</p>

<blockquote>
<p>a future life that&rsquo;s reached the technological limit needs mainly one fundamental resource: so called baryonic matter, meaning anything made up of atoms or their constituents (quarks and electrons)&rdquo; because such a civilization would be able to synthesize any other matter from a set of primitive constituents. Or even transform matter into energy with a very high efficiency.</p>
</blockquote>

<h3 id="energy-efficiency">Energy efficiency</h3>

<p>Matter is energy (E = mc^). What matters is how efficiently you are able to convert matter into energy. Currently, which nuclear fusion, we can reach 0.7 % of officiency&hellip;!</p>

<p><img src="https://supitalp.github.io/tldr/images/life-3.0-energy-efficiency.png" alt="Energy efficiency" style="width: 100%;"/></p>

<h3 id="computing-speed-is-limited-by-energy">Computing speed is limited by energy</h3>

<ul>
<li>Performing an elementary logical operation in time t requires an average energy of E = h/4T (Seth Lloyd)</li>
</ul>

<h3 id="interaction-between-potential-super-ai-civilizations-cosmic-hierarchies">Interaction between potential super AI civilizations? &ldquo;Cosmic Hierarchies&rdquo;</h3>

<blockquote>
<p>So if life engulfs our cosmos, what form will it choose: simple and fast, or complex and slow? I predict that it will make the same choice as Earth life has made: both! The denizens of Earth’s biosphere span a stagger­ing range of sizes, from gargantuan two-hundred-ton blue whales down to the petite 10-16 kg bacterium Pelagibacter, believed to account for more biomass than all the world’s fish combined. Moreover, organisms that are large, complex and slow often mitigate their sluggishness by containing smaller modules that are simple and fast. For example, your blink reflex is extremely fast precisely because it’s implemented by a small and simple circuit that doesn’t involve most of your brain: if that hard-to-swat fly accidentally heads toward your eye, you’ll blink within a tenth of a second, long before the relevant information has had time to spread throughout your brain and make you consciously aware of what happened</p>

<p>On Earth, trade has been a traditional driver of cooperation because the relative difficulty of producing things varies across the planet. However, if super­intelligence develops technology that can readily re­arrange elementary particles into any form of matter whatsoever, then it will eliminate most of the incentive for long-distance travel.</p>

<p>in a cosmos teeming with super­intelligence, almost the only commodity worth shipping long distances will be information&rdquo;. &ldquo;Hedonistic life forms may want awesome digital entertainment and simulated experiences, and cosmic commerce may fuel demand for some form of cosmic cryptocurrency in the spirit of bit­coins</p>

<p>After all, information is very different from the resources that humans usually fight over, in that you can simultaneously give it away and keep it.</p>
</blockquote>

<h3 id="is-there-any-other-life-form-than-us-in-the-universe">Is there any other life form than us in the universe?</h3>

<p>Max Tegmark&rsquo;s personal intuition is that we are the only life form in our reachable/observable universe. However, the argument that supports his intuition is completely dubious&hellip;! Indeed, he reasons in terms of logarithmic scale which does not make any mathematical sense. Imagine that I am looking for a life form on a line of length 100 km (10^5 meters), and that I tell you, after having explored 1 meter, that it is unlikely that I find anything in the narrow range between 1 m (10^0 m) and 100 km (10^5 m)? That would sound completely ridiculous, right. Things get even worse because we are actually interested in the <strong>volume</strong> of space that has been explored, not just the linear distance&hellip; I was very disappointed to read this argument. It casts a doubt in my optinion on the general validity of all the other scientific works being presented in the book. Maybe I understood something wrong with this demonstration?</p>

<blockquote>
<p>For our nearest neighbor civilization to be within our Universe, whose radius is about 10^26 meters, the number of zeroes can’t exceed 26, and the probability of the number of zeroes falling in the narrow range between 22 and 26 is rather small. This is why I think we’re alone in our Universe</p>
</blockquote>

<p><img src="https://supitalp.github.io/tldr/images/life-3.0-extraterrestrial-life.png" alt="Are we alone in the universe? Dubious proof" style="width: 100%;"/></p>

<blockquote>
<p>It’s important not to be overly anthropocentric when searching for advanced life: if we discover an extraterrestrial civilization, it’s likely to already have gone super­intelligent. As Martin Rees put it in a recent essay, “the history of human technological civilization is measured in centuries—and it may be only one or two more centuries before humans are over­taken or transcended by inorganic intelligence, which will then persist, continuing to evolve, for billions of years….We would be most unlikely to ‘catch’ it in the brief sliver of time when it took organic form</p>
</blockquote>

<h2 id="goals">Goals</h2>

<p>An entire chapter is dedicated to goals: what goals would a potential super AI have? What is a goal, where do they come from? Can we identify possible goals that any intelligent civilization would have?</p>

<blockquote>
<p>If I had to summarize in a single word what the thorniest AI controversies are about, it would be “goals”: Should we give AI goals, and if so, whose goals? How can we give AI goals? Can we ensure that these goals are re­tained even if the AI gets smarter? Can we change the goals of an AI that’s smarter than us? What are our ultimate goals?</p>
</blockquote>

<h3 id="physics-the-origin-of-goals">Physics: The Origin of Goals</h3>

<blockquote>
<p>How did such goal-oriented behavior emerge from the physics of our early Universe, which consisted merely of a bunch of particles bouncing around seemingly without goals?</p>
</blockquote>

<p>An example: light travels in a manner that *seemingly** minimizes the travel time (Fermat&rsquo;s principle).</p>

<blockquote>
<p>We naturally interpret her choice of trajectory as goal-oriented, since out of all possible trajectories, she’s deliberately choosing the optimal one that gets her to the swimmer as fast as possible. Yet a simple light ray similarly bends when it enters water, also minimizing the travel time to its destination! This is known in physics as Fermat’s principle, articulated in 1662, and it provides an alternative way of predicting the behavior of light rays. Remarkably, physicists have since discovered that all laws of classical physics can be mathematically reformulated in an analogous way: out of all ways that nature could choose to do something, it prefers the optimal way, which typically boils down to minimizing or maximizing some quantity.</p>

<p>One famous quantity that nature strives to maximize is entropy.</p>
</blockquote>

<p>While maximizing entropy would lead to an &ldquo;inexorable progression toward heat death&rdquo;, there are good news: (i) gravity &ldquo;strives to make our universe more clumpy and interesting&rdquo;, and (ii):</p>

<blockquote>
<p>Second, recent work by my MIT colleague Jeremy England and others has brought more good news, showing that thermodynamics also endows nature with a goal more inspiring than heat death.1 This goal goes by the geeky name dissipation-driven adaptation, which basically means that random groups of particles strive to organize themselves so as to extract energy from their environment as efficiently as possible (“dissipation” means causing entropy to increase, typically by turning useful energy into heat, often while doing useful work in the process). For example, a bunch of molecules exposed to sunlight would over time tend to arrange themselves to get better and better at absorbing sunlight. In other words, nature appears to have a built-in goal of producing self-organizing systems that are increasingly complex and lifelike, and this goal is hardwired into the very laws of physics.</p>

<p>in the famous 1944 book What’s Life? by Erwin Schrödinger, one of the founders of quantum mechanics. Schrödinger pointed out that a hallmark of a living system is that it maintains or reduces its entropy by increasing the entropy around it. In other words, the second law of thermodynamics has a life loophole: although the total entropy must increase, it’s allowed to decrease in some places as long as it increases even more elsewhere. So life maintains or increases its complexity by making its environment messier.</p>
</blockquote>

<h3 id="biology-the-evolution-of-goals">Biology: The Evolution of Goals</h3>

<p>Physics drives particles to arrange themselves so as to extract energy as efficiently as possible. One good way of doing this is through self-replication. Biology seemed to have concentrated on this goal: the new goal is not dissipation, but replication:</p>

<blockquote>
<p>If you had been quietly observing Earth around the time when life got started, you would have noticed a dramatic change in goal-oriented behavior. Whereas earlier, the particles seemed as though they were trying to increase average messiness in various ways, these newly ubiquitous self-copying patterns seemed to have a different goal: not dissipation but replication</p>
</blockquote>

<p>Concept of &ldquo;bounded rationality&rdquo;: the fact the agents make decisions based on their limited resources / available information:</p>

<blockquote>
<p>In practice, these agents have what Nobel laureate and AI pioneer Herbert Simon termed “bounded rationality” because they have limited resources: the rationality of their decisions is limited by their available information, their available time to think and their available hardware with which to think</p>
</blockquote>

<h3 id="friendly-ai-aligning-goals">Friendly AI: Aligning Goals</h3>

<p>Whatever the ultimate goals of an AI may be, they will lead to predictable subgoals:</p>

<p><img src="https://supitalp.github.io/tldr/images/life-3.0-subgoals.png" alt="Subgoals of any AI" style="width: 100%;"/></p>

<blockquote>
<p>Moreover, in its attempts to better model the world, the AI may naturally, just as we humans have done, attempt also to model and understand how it itself works—in other words, to self-reflect. Once it builds a good self-model and understands what it is, it will understand the goals we have given it at a meta level, and perhaps choose to disregard or subvert them in much the same way as we humans understand and deliberately subvert goals that our genes have given us, for example by using birth control.</p>
</blockquote>

<h3 id="ethics-choosing-goals">Ethics: Choosing Goals</h3>

<blockquote>
<p>do there exist some sort of consensus goals that form a good compromise for humanity as a whole?</p>
</blockquote>

<p>The four universal preferences:</p>

<blockquote>
<p>Utilitarianism: Positive conscious experiences should be maximized and suffering should be minimized.</p>

<p>Diversity: A diverse set of positive experiences is better than many repetitions of the same experience, even if the latter has been identified as the most positive experience possible.</p>

<p>Autonomy: Conscious entities/societies should have the freedom to pursue their own goals unless this conflicts with an overriding principle.</p>

<p>Legacy: Compatibility with scenarios that most humans today would view as happy, incompatibility with scenarios that essentially all humans today would view as terrible.</p>
</blockquote>

<h3 id="ultimate-goals">Ultimate Goals?</h3>

<blockquote>
<p>the pursuit of truth (a more accurate world model) is simply a subgoal of almost any ultimate goal</p>

<p>Some may even dismiss everything we call “human values” as nothing but a cooperation protocol, helping us with the subgoal of collaborating more efficiently</p>
</blockquote>

<p>Nick Bostrom&rsquo;s <em>orthogonality thesis</em> presented in his book <em>Superintelligence</em>: the ultimate goals of a system can be independent of its intelligence.</p>

<h2 id="consciousness">Consciousness</h2>

<h3 id="where-is-consciousness">Where is Consciousness?</h3>

<blockquote>
<p>More shockingly, your consciousness doesn’t appear to extend to your cerebellum which contains about two-thirds of all your neurons: patients whose cerebellum is destroyed experience slurred speech and clumsy motion reminiscent of a drunkard, but remain fully conscious.</p>

<p>Intriguingly, you can often react to things faster than you can become conscious of them, which proves that the information processing in charge of your most rapid reactions must be unconscious. For example, if a foreign object approaches your eye, your blink reflex can close your eyelid within a mere tenth of a second. It’s as if one of your brain systems receives ominous information from the visual system, computes that your eye is in danger of getting struck, emails your eye muscles instructions to blink and simultaneously emails the conscious part of your brain saying “Hey, we’re going to blink.” By the time this email has been read and included into your conscious experience, the blink has already happened.</p>

<p>It takes longer for you to analyze images than sounds because it’s more complicated—which is why Olympic races are started with a bang rather than with a visual cue.</p>
</blockquote>

<h3 id="theories-of-consciousness">Theories of Consciousness</h3>

<blockquote>
<p>What particle arrangements are conscious?</p>

<p>How can something as complex as consciousness be made of something as simple as particles? I think it’s because it’s a phenomenon that has properties above and beyond those of its particles. In physics, we call such phenomena “emergent.” Let’s understand this by looking at an emergent phenomenon that’s simpler than consciousness: wetness. A drop of water is wet, but an ice crystal and a cloud of steam aren’t, even though they’re made of identical water molecules. Why? Because the property of wetness depends only on the arrangement of the molecules. It makes absolutely no sense to say that a single water molecule is wet, because the phenomenon of wetness emerges only when there are many molecules, arranged in the pattern we call liquid. So solids, liquids and gases are all emergent phenomena: they’re more than the sum of their parts, because they have properties above and beyond the properties of their particles. They have properties that their particles lack.</p>

<p>So could there be analogous quantities that quantify consciousness? The Italian neuroscientist Giulio Tononi has proposed one such quantity, which he calls the “integrated information,” denoted by the Greek letter Φ (Phi), which basically measures how much different parts of a system know about each other.</p>

<p>Giulio and his collaborators have measured a simplified version of Φ by using EEG to measure the brain’s response to magnetic stimulation. Their “consciousness detector” works really well: it determined that patients were conscious when they were awake or dreaming, but unconscious when they were anesthetized or in deep sleep. It even discovered consciousness in two patients suffering from “locked-in” syndrome, who couldn’t move or communicate in any normal way. So this is emerging as a promising technology for doctors in the future to figure out whether certain patients are conscious or not.</p>
</blockquote>

<p><a href="https://www.youtube.com/watch?v=WmzU47i2xgw">Video of Clive Wearing, who appears perfectly conscious even though his memories last less than a minute.</a></p>

<blockquote>
<p>As we saw above, the unconscious information processing in our human brains appears linked to the effortless, fast and automatic way of thinking that psychologists call &ldquo;System 1&rdquo;.</p>

<p>as emphasized by Seth Lloyd, there’s a famous computer-science theorem saying that for almost all computations, there’s no faster way of determining their outcome than actually running them.</p>

<p>Some people tell me that they find causality degrading, that it makes their thought processes meaningless and that it renders them “mere” machines. I find such negativity absurd and unwarranted. First of all, there’s nothing “mere” about human brains, which, as far as I’m concerned, are the most amazingly sophisticated physical objects in our known Universe. Second, what alternative would they prefer? Don’t they want it to be their own thought processes (the computations performed by their brains) that make their decisions? Their subjective experience of free will is simply how their computations feel from inside: they don’t know the outcome of a computation until they’ve finished it. That’s what it means to say that the computation is the decision.</p>
</blockquote>

<h3 id="meaning">Meaning</h3>

<blockquote>
<p>Traditionally, we humans have often founded our self-worth on the idea of human exceptionalism: the conviction that we’re the smartest entities on the planet and therefore unique and superior. The rise of AI will force us to abandon this and become more humble.</p>

<p>we see that although we’ve focused on the future of intelligence in this book, the future of consciousness is even more important, since that’s what enables meaning.</p>
</blockquote>

<h2 id="epilogue-the-tale-of-the-fli-team">Epilogue: The Tale of the FLI Team</h2>

<blockquote>
<p>So in parallel with discovering what we are, are we inevitably making ourselves obsolete? That would be poetically tragic.</p>

<p>This is why we need more mindful optimists. And this is why I&rsquo;ve encouraged you throughout this book to think about what sort of future you want rather than merely what sort of future you fear, so that we can find shared goals to plan and work for.</p>
</blockquote>

<h2 id="vocabulary">Vocabulary</h2>

<ul>
<li>teeming</li>
<li>thorny</li>
<li>scathing</li>
<li>quibbling</li>
</ul>
</div>
  </div>

  <footer class="article-footer">
    <div class="content-inner">

      <nav class="p-crumb">
        <ol>
          <li><a href="https://supitalp.github.io/tldr/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
          
          <li itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="https://supitalp.github.io/tldr/post/" itemprop="url"><span itemprop="title">post</span></a></li>
          
          <li class="active">Life 3.0 - Being Human in the Age of Artificial Intelligence</li>
        </ol>
      </nav>

      
      
      
      
      
      
    </div>
  </footer>

</article>


    
  </div>

  <div class="col-md-4">
    <aside class="site">

  <section>
    <header>latests</header>
    <div>
      <div class="row">
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/le-pere-goriot/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/le-pere-goriot.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/le-pere-goriot/">Le Père Goriot</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-08-20T09:00:00JST">Aug 20, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/the-subtle-art-of-not-giving-a-fck/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/the-subtle-art-of-not-giving-a-f*ck.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/the-subtle-art-of-not-giving-a-fck/">The Subtle Art of Not Giving a F*ck</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-08-14T09:00:00JST">Aug 14, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        <div class="col-sm-12"></div>
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/factfulness/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/factfulness.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/factfulness/">Factfulness</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-08-09T09:00:00JST">Aug 9, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/antarctique-le-reve-d-une-vie/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/antarctique-le-reve-d-une-vie.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/antarctique-le-reve-d-une-vie/">L&#39;Antarctique, le Rêve d&#39;une Vie</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-07-31T09:00:00JST">Jul 31, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        <div class="col-sm-12"></div>
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/origin/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/origin.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/origin/">Origin</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-07-28T09:00:00JST">Jul 28, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/le-livre-des-baltimore/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/le-livre-des-baltimore.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/le-livre-des-baltimore/">Le livre des Baltimore</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-07-25T09:00:00JST">Jul 25, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        <div class="col-sm-12"></div>
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/homo-deus/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/homo-deus.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/homo-deus/">Homo Deus</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-05-01T09:00:00JST">May 1, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/vouloir-toucher-les-etoiles/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/vouloir-toucher-les-etoiles.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/vouloir-toucher-les-etoiles/">Vouloir toucher les étoiles</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-05-01T09:00:00JST">May 1, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        <div class="col-sm-12"></div>
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/berezina/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/berezina.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/berezina/">Berezina</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-04-01T09:00:00JST">Apr 1, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        
        
        <div class="col-md-12 col-sm-6 col-xs-12"><article class="li sm">
  <a href="https://supitalp.github.io/tldr/post/les-derniers-jours-de-nos-peres/" class="thumb" style="background-image: url(https://supitalp.github.io/tldr/images/les-derniers-jours-de-nos-peres.jpg);"></a>
  <header>
    <div class="title"><a href="https://supitalp.github.io/tldr/post/les-derniers-jours-de-nos-peres/">Les derniers jours de nos pères</a></div>

    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-03-25T09:00:00JST">Mar 25, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://supitalp.github.io/tldr/post/">post</a></li>
    </ul>
  </header>
</article>
</div>
        <div class="col-sm-12"></div>
        
      </div>
    </div>
  </section>

</aside>

  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; tl;dr</span></p>
        <aside>
          <p>Powered by <a href="https://gohugo.io/">Hugo</a>.</p>
          <p><a href="https://github.com/dim0627/hugo_theme_robust">Robust</a> designed by <a href="http://yet.unresolved.xyz/">Daisuke Tsuji</a>.</p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

